{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c0b080-e68e-4c84-80bb-a41711ea0a68",
   "metadata": {},
   "source": [
    "# Generate Test Data for Evaluating our ML Models\n",
    "---\n",
    "__Note__\n",
    "* We are currently looking at MLP Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2999c626-57bc-47c1-99ad-017e45fe686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Note: Test if there is a GPU Available for Torch\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b18db3-6aae-4b95-b459-5d018472f31f",
   "metadata": {},
   "source": [
    "# Create sample dataset to test multiclass classifier\n",
    "\n",
    "__Create a simple pattern that the ML can find in the data__\n",
    "\n",
    "[000,40,__20,20__,49,97,16,86,__20__]\n",
    "\n",
    "[998,09,15,__30,30__,33,98,43,__30__]\n",
    "\n",
    "[003,93,92,62,__40,40__,24,10,__40__]\n",
    "\n",
    "[004,04,28,54,12,__50,50__,47,__50__]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48b8947-d4f6-44e3-88e0-97d3a2d235c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wormbase_id</th>\n",
       "      <th>EE</th>\n",
       "      <th>LE</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>YA</th>\n",
       "      <th>category_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>88</td>\n",
       "      <td>54</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>19</td>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>69</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>75</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>93</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>77</td>\n",
       "      <td>37</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>17</td>\n",
       "      <td>75</td>\n",
       "      <td>66</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>93</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     wormbase_id  EE  LE  L1  L2  L3  L4  YA  category_1\n",
       "0              0   7  48  30  30   9  88  54          30\n",
       "1              1  10  10  71  17  38  62  68          10\n",
       "2              2  10  10  42  19  54  14  61          10\n",
       "3              3  79  88  80  40  40  38  69          40\n",
       "4              4  15   7  37   5  50  50  94          50\n",
       "..           ...  ..  ..  ..  ..  ..  ..  ..         ...\n",
       "995          995  10  10  29  83  11   8  68          10\n",
       "996          996  72  46  75  54  50  50  47          50\n",
       "997          997  93  20  20  29  47  44   6          20\n",
       "998          998  77  37  63   2  50  50   7          50\n",
       "999          999  17  75  66  18  50  50  93          50\n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple pattern that the ML can find in the data\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Set \"display.max_rows\" to \"None\" to see all rows in the output\n",
    "pd.set_option(\"display.max_rows\", 100) \n",
    "\n",
    "# Create a list of 7 items from 1 to 100\n",
    "random_list = random.sample(range(1, 101), 7)\n",
    "\n",
    "# Add a pttern into the data that should be discoverable by the ML program\n",
    "# The pattern randomly puts two number ajacent to each other and sets that as the target\n",
    "# Example:\n",
    "\n",
    "test_data_dict = {}\n",
    "pos=0\n",
    "for index in range(0,1000):\n",
    "    \n",
    "    rl = random.sample(range(1, 101), 8)\n",
    "    idx = random.sample(range(0, 6), 1)[0]\n",
    "     \n",
    "    rl[idx]=(idx+1)*10\n",
    "    rl[idx+1]=(idx+1)*10\n",
    "    rl[7]=(idx+1)*10\n",
    "\n",
    "    # Using classical_life_stage format for testing the ML\n",
    "    test_data_dict[index] = {'wormbase_id':index,'EE':rl[0],'LE':rl[1],'L1':rl[2],'L2':rl[3],'L3':rl[4],'L4':rl[5],'YA':rl[6],'category_1':rl[7]}\n",
    "                                           \n",
    "test_data = pd.DataFrame.from_dict(test_data_dict, orient='index')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f7a726-9efe-4ce0-a1ee-255deda570af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break the dataset into Train Test and save\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "out_dir ='./output_data/output_classical_life_stage'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "target = test_data['category_1']\n",
    "features = test_data.drop('category_1', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features,\n",
    "                                                    target,\n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=42)\n",
    "# Add the Target back before saving\n",
    "x_train = x_train.assign(category_1=y_train.values)\n",
    "x_test = x_test.assign(category_1=y_test.values)\n",
    "\n",
    "\n",
    "# Show the results of the split\n",
    "print(f\"Training set has {x_train.shape[0]:,d} samples.\")\n",
    "print(f\"Testing set has {x_test.shape[0]:,d} samples.\")\n",
    "print(f\"Total set has {x_test.shape[0] + x_train.shape[0]:,d} samples.\")\n",
    "print(f\"Total Features {x_test.shape[1]-1:,d}.\")\n",
    "\n",
    "x_train.to_csv(out_dir + '/test_classical_life-train.csv', index=None, header=True)\n",
    "x_test.to_csv(out_dir + '/test_classical_life-test.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726ccfbd-6158-4c18-a8fd-54eece88216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the test data\n",
    "test_classical_life['category_1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8507c0-6590-4dc7-a94a-6d91003e979c",
   "metadata": {},
   "source": [
    "# Execute against test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a9f44-c4e2-4d93-811a-f097ea452f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Training methods from a file\n",
    "from multiclass_classifier import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f8c6d-a842-4e35-843e-2bf655542bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MultiClassClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiClassClassifier, self).__init__()\n",
    "        self.hidden_1 = nn.Linear(7, 50)  # Input layer -> Hidden layer\n",
    "        self.output = nn.Linear(50, 6) # SET_DATA_SET\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden_1(x))\n",
    "        #x = torch.softmax(self.output(x), dim=1)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Define a method to get the data to train with\n",
    "def get_life_stages_data(base_dir=BASE_DIR, data_type='train'):\n",
    "    file_name_prefix='test_classical_life'\n",
    "    data_set = pd.read_csv(f\"./output_data/{base_dir}/{file_name_prefix}-{data_type}.csv\")\n",
    "    print(f\"{file_name_prefix}-{data_type}.shape {data_set.shape}\")\n",
    "                       \n",
    "    target_label = 'category_1'\n",
    "    x_train = data_set.drop(target_label, axis=1)\n",
    "    x_train = x_train.drop('wormbase_id', axis=1)\n",
    "    \n",
    "    y_train = data_set[target_label]\n",
    "    y_train = y_train.to_frame()\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(y_train)\n",
    "    y_train = one_hot_encoder.transform(y_train)\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    x_train = torch.from_numpy(x_train.values).float()\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "\n",
    "    return x_train, y_train, one_hot_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a287ab-2a66-43b3-b114-1aad5a4b5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One pass Train and Validate\n",
    "x_train, y_train, one_hot_encoder = get_life_stages_data(BASE_DIR)\n",
    "x_test, y_test, _ = get_life_stages_data(BASE_DIR, data_type='test')\n",
    "\n",
    "model = MultiClassClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_loader, validation_loader = get_dataloaders(\n",
    "                    x_train, y_train, x_test, y_test, \n",
    "                    train_shuffle = True, validation_shuffle = True)\n",
    "\n",
    "\n",
    "for batch_idx, (x_validation, y_validation) in enumerate(validation_loader):\n",
    "    print(f'{x_validation[0]=} {len(y_validation[0])=}')\n",
    "    \n",
    "for batch_idx, (x_train, y_train) in enumerate(train_loader):\n",
    "    print(f'{x_train[0]=} {len(y_train[0])=}')\n",
    "    \n",
    "ret_val = train_validate(model, criterion, optimizer, train_loader, validation_loader, n_epochs=300)\n",
    "train_losses, train_accuracies, validation_losses, validation_accuracies  = ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed9cab-6524-4406-96c0-a618bf61f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Plot the training curve\n",
    "plot_learning_curve2(train_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a249c-6ae5-48d8-a77c-deaf8206aab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Run cross-valivation once with all the data\n",
    "\n",
    "x_train, y_train, one_hot_encoder = get_life_stages_data(BASE_DIR)\n",
    "x_test, y_test, _ = get_life_stages_data(BASE_DIR, data_type='test')\n",
    "\n",
    "model = MultiClassClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "ret_val = cross_validation_training(x_train, y_train, model, criterion, optimizer, k=5,shuffle=False, n_epochs=100)\n",
    "train_losses, train_accuracies, validation_losses, validation_accuracies = ret_val\n",
    "\n",
    "\n",
    "plot_learning_curve2(train_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2c777-b8f4-49cb-b9dd-2fc5b49befae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Run cross-valivation once with with different amounts of data\n",
    "\n",
    "x_train, y_train, one_hot_encoder = get_life_stages_data(BASE_DIR)\n",
    "x_test, y_test, one_hot_encoder = get_life_stages_data(BASE_DIR, data_type='test')\n",
    "\n",
    "model = MultiClassClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_losses_lst =[]\n",
    "train_accuracies_lst =[]\n",
    "validation_losses_lst =[]\n",
    "validation_accuracies_lst =[]\n",
    "for percentage in [20,40,60,80,100]:\n",
    "    print(f\"Training with {percentage}% of data\")\n",
    "    x_data, y_data = get_percent_of_data(x_train, y_train, percentage)\n",
    "    ret_val = cross_validation_training(x_data, y_data, model, criterion, optimizer, k=5,shuffle=False, n_epochs=300)\n",
    "    train_losses, train_accuracies, validation_losses, validation_accuracies = ret_val\n",
    "    train_losses_lst.append(train_losses)\n",
    "    train_accuracies_lst.append(train_accuracies)\n",
    "    validation_losses_lst.append(validation_losses)\n",
    "    validation_accuracies_lst.append(validation_accuracies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9180ab-ae08-43bf-b436-7b5e299f95e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Training methods from a file\n",
    "\n",
    "def plot_learning_curve(train_sizes, train_scores_lst, test_scores_lst, y_title=\"Score\",y_as_percentage=True):\n",
    "    plt.figure()\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.xlabel(\"% of training examples\")\n",
    "    plt.ylabel(y_title)\n",
    "    \n",
    "    train_scores = np.array(train_scores_lst)\n",
    "    test_scores = np.array(test_scores_lst)\n",
    "    \n",
    "    if y_as_percentage:\n",
    "        print(\"WE ARE HERE\")\n",
    "        plt.ylim(top=110)\n",
    "        train_scores = train_scores * 100\n",
    "        test_scores = test_scores * 100\n",
    "        \n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, '^--', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt, train_scores_mean, test_scores_mean\n",
    "        \n",
    "#print(train_accuracies_lst)\n",
    "print(validation_accuracies_lst)\n",
    "ret_val = plot_learning_curve([20,40,60,80,100], train_accuracies_lst, validation_accuracies_lst, y_title=\"Score (Accuracy)\")\n",
    "plt, train_scores_mean, test_scores_mean = ret_val\n",
    "print(f\"{train_scores_mean=}\")\n",
    "print(f\"{test_scores_mean=}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396f4532-b1f0-498c-87b3-4479437809ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = create_results_df(model, x_train,y_train, one_hot_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45406a7-00ec-4c44-badf-5fd80b27b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = create_results_df(model, x_test,y_test, one_hot_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c6de0a-94d8-46b3-b797-a8d28f267a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a58db03-cf86-4fca-b247-41f8379505ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_pred = model(x_test)\n",
    "\n",
    "def get_one_hot(arr):\n",
    "    # Find the index of the maximum value in the array\n",
    "    max_index = np.argmax(arr)\n",
    "    # Create a new array of zeros with the same shape as the input array\n",
    "    one_hot = np.zeros_like(arr)\n",
    "    # Set the index of the maximum value to 1\n",
    "    one_hot[max_index] = 1\n",
    "    return one_hot\n",
    "\n",
    "y_pred = model(x_test)\n",
    "y_pred = y_pred.detach().numpy()\n",
    "y_pred = np.apply_along_axis(get_one_hot, axis=1, arr=y_pred)\n",
    "y_pred\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 score: {:.2f}\".format(f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a46f5c-c0e7-4431-8e32-dec071da8329",
   "metadata": {},
   "source": [
    "# Iris data test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df5768-9d68-4613-837b-86cdef521418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data for this project\n",
    "!wget -O ./output_data/iris-train.csv https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
    "# Original data has no header\n",
    "!echo \"pl,pw,sl,sw,flower\" | cat - ./output_data/iris-train.csv > temp && mv temp ./output_data/iris-train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a209b-3952-4f89-bdf8-bef5d7871412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import platform\n",
    "import math\n",
    "import os \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils_data\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "base_dir='./output_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368374a5-4546-4dbb-bf6e-af28fa01f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiclass_classifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a2f13-81f7-45b7-85e2-74c90b5e711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiClassClassifier, self).__init__()\n",
    "        self.hidden_1 = nn.Linear(4, 8)  # Input layer -> Hidden layer\n",
    "        self.output = nn.Linear(8, 3) # Hidden layer -> Output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden_1(x))\n",
    "        x = torch.softmax(self.output(x), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_iris_data(base_dir=base_dir, data_type='train'):\n",
    "    data_set = pd.read_csv(f\"{base_dir}/iris-{data_type}.csv\")\n",
    "    print(f\"iris-{data_type}.shape {data_set.shape}\")\n",
    "                       \n",
    "    target_label = 'flower'\n",
    "    x_train = data_set.drop(target_label, axis=1)\n",
    "    \n",
    "    y_train = data_set[target_label]\n",
    "    y_train = y_train.to_frame()\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(y_train)\n",
    "    y_train = one_hot_encoder.transform(y_train)\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    x_train = torch.from_numpy(x_train.values).float()\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    #y_train= y_train.unsqueeze(1)\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "x_train, y_train = get_iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c456b-d1dd-41c0-95e4-2ad16252d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = get_iris_data()\n",
    "x_test, y_test = get_iris_data()\n",
    "model = MultiClassClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "train_loader, validation_loader = get_dataloaders(\n",
    "                    x_train, y_train, x_test, y_test, \n",
    "                    train_shuffle = False, validation_shuffle = False)\n",
    "\n",
    "for batch_idx, (x_validation, y_validation) in enumerate(validation_loader):\n",
    "    print(f'{x_validation[0]=} {len(y_validation[0])=}')\n",
    "    \n",
    "for batch_idx, (x_train, y_train) in enumerate(train_loader):\n",
    "    print(f'{x_train[0]=} {len(y_train[0])=}')\n",
    "    \n",
    "    \n",
    "train_losses, validation_losses, validation_accuracies = train_validate(model, criterion, optimizer, train_loader, validation_loader, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36595aba-41f9-4e24-8ea3-3fcda19465f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "x_train, y_train = get_iris_data()\n",
    "x_test, y_test = get_iris_data()\n",
    "model = MultiClassClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "ret_val = cross_validation_training(x_train, y_train, model, criterion, optimizer, k=5, shuffle=True, n_epochs=100)\n",
    "train_losses, validation_losses, validation_accuracies = ret_val\n",
    "\n",
    "\n",
    "plot_learning_curve2(train_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43190290-d828-4ab6-9554-df3b84e41273",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_correct=0\n",
    "for i in range(len(x_test)-1):\n",
    "    x_batch = x_test[i:i+1]\n",
    "    predicted = model(x_batch)\n",
    "    #print(f'{X_batch} {predicted} {y_batch[i:i+1]}')\n",
    "    p_a = torch.argmax(predicted, 1)[0]\n",
    "    t_a = torch.argmax(y_test[i:i+1],1)[0]\n",
    "    print(f'{i:<3} {p_a} {t_a} {p_a==t_a}')\n",
    "    if p_a==t_a:\n",
    "        total_correct +=1\n",
    "\n",
    "print(f'Score {total_correct/len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462aa4e1-b2dc-4591-9484-43963c543c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dan-dev-sc]",
   "language": "python",
   "name": "conda-env-dan-dev-sc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
